{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'colab'\n",
    "import einops\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from functools import partial\n",
    "import tqdm.auto as tqdm\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import EasyTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting functions\n",
    "# This is mostly a bunch of over-engineered mess to hack Plotly into producing \n",
    "# the pretty pictures I want, I recommend not reading too closely unless you \n",
    "# want Plotly hacking practice\n",
    "def to_numpy(tensor, flat=False):\n",
    "    if type(tensor)!=torch.Tensor:\n",
    "        return tensor\n",
    "    if flat:\n",
    "        return tensor.flatten().detach().cpu().numpy()\n",
    "    else:\n",
    "        return tensor.detach().cpu().numpy()\n",
    "def imshow(tensor, xaxis=None, yaxis=None, animation_name='Snapshot', **kwargs):\n",
    "    tensor = torch.squeeze(tensor)\n",
    "    px.imshow(to_numpy(tensor, flat=False), \n",
    "              labels={'x':xaxis, 'y':yaxis, 'animation_name':animation_name}, \n",
    "              **kwargs).show()\n",
    "# Set default colour scheme\n",
    "# Creates good defaults for showing divergent colour scales (ie with both \n",
    "# positive and negative values, where 0 is white)\n",
    "imshow = partial(imshow, color_continuous_scale='RdBu', color_continuous_midpoint=0.0)\n",
    "\n",
    "def line(x, y=None, hover=None, xaxis='', yaxis='', **kwargs):\n",
    "    if type(y)==torch.Tensor:\n",
    "        y = to_numpy(y, flat=True)\n",
    "    if type(x)==torch.Tensor:\n",
    "        x=to_numpy(x, flat=True)\n",
    "    fig = px.line(x, y=y, hover_name=hover, **kwargs)\n",
    "    fig.update_layout(xaxis_title=xaxis, yaxis_title=yaxis)\n",
    "    fig.show()\n",
    "def scatter(x, y, **kwargs):\n",
    "    px.scatter(x=to_numpy(x, flat=True), y=to_numpy(y, flat=True), **kwargs).show()\n",
    "def lines(lines_list, x=None, mode='lines', labels=None, xaxis='', yaxis='', title = '', log_y=False, hover=None, **kwargs):\n",
    "    # Helper function to plot multiple lines\n",
    "    if type(lines_list)==torch.Tensor:\n",
    "        lines_list = [lines_list[i] for i in range(lines_list.shape[0])]\n",
    "    if x is None:\n",
    "        x=np.arange(len(lines_list[0]))\n",
    "    fig = go.Figure(layout={'title':title})\n",
    "    fig.update_xaxes(title=xaxis)\n",
    "    fig.update_yaxes(title=yaxis)\n",
    "    for c, line in enumerate(lines_list):\n",
    "        if type(line)==torch.Tensor:\n",
    "            line = to_numpy(line)\n",
    "        if labels is not None:\n",
    "            label = labels[c]\n",
    "        else:\n",
    "            label = c\n",
    "        fig.add_trace(go.Scatter(x=x, y=line, mode=mode, name=label, hovertext=hover, **kwargs))\n",
    "    if log_y:\n",
    "        fig.update_layout(yaxis_type=\"log\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = EasyTransformer.from_pretrained('gpt2') # This loads GPT-2 Small, with 80M parameters. \n",
    "# gpt2-medium, gpt2-large, gpt2-xl give larger sizes, see the demo notebook for more\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x2cdd24cd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"After John and Mary went to the shops, Mary handed a bottle of milk to\" # @param\n",
    "example_answer = \" John\" #@param\n",
    "# Hacky function to map a text string to separate tokens as text\n",
    "example_prompt_str_tokens = model.to_str_tokens(example_prompt, prepend_bos=True)\n",
    "example_answer_str_tokens = model.to_str_tokens(example_answer)\n",
    "print(\"Tokenized prompt:\", example_prompt_str_tokens)\n",
    "print(\"Tokenized answer:\", example_answer_str_tokens)\n",
    "prompt_length = len(example_prompt_str_tokens)\n",
    "answer_length = len(example_answer_str_tokens)\n",
    "example_logits = model(example_prompt+example_answer)\n",
    "for index in range(prompt_length, prompt_length + answer_length):\n",
    "    print(\"Logits for token:\", example_answer_str_tokens[index - prompt_length])\n",
    "    token_logits = example_logits[0, index-1]\n",
    "    probs = torch.nn.functional.softmax(token_logits, dim=-1)\n",
    "    values, indices = token_logits.sort(descending=True)\n",
    "    for i in range(10):\n",
    "        print(f\"Top {i}th logit. Logit: {values[i].item():.6} Prob: {probs[indices[i]].item():.2%} Token: |{model.tokenizer.decode(indices[i])}|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input split into tokens: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shops', ',', ' Mary', ' handed', ' a', ' bottle', ' of', ' milk', ' to']\n",
      "Index of John token: 1757. Index of Mary token: 5335\n",
      "Input text: After John and Mary went to the shops, Mary handed a bottle of milk to, John logit - Mary logit: 4.0183610916137695\n",
      "Input text: After John and Mary went to the shops, John handed a bottle of milk to, John logit - Mary logit: -2.918598175048828\n"
     ]
    }
   ],
   "source": [
    "example_text = \"After John and Mary went to the shops, Mary handed a bottle of milk to\"\n",
    "example_text_reverse = \"After John and Mary went to the shops, John handed a bottle of milk to\"\n",
    "example_str_tokens = model.to_str_tokens(example_text, prepend_bos=True)\n",
    "print(\"Input split into tokens:\", example_str_tokens)\n",
    "john_index = model.tokenizer.encode(\" John\")[0]\n",
    "mary_index = model.tokenizer.encode(\" Mary\")[0]\n",
    "print(f\"Index of John token: {john_index}. Index of Mary token: {mary_index}\")\n",
    "\n",
    "def get_logit_diff(logits):\n",
    "    # Takes in a batch x position x vocab tensor of logits, and returns the difference between the John and Mary logit\n",
    "    return logits[0, -1, john_index] - logits[0, -1, mary_index]\n",
    "example_logits = model(example_text) # Shape batch x position x vocab\n",
    "example_logit_diff = get_logit_diff(example_logits)\n",
    "example_logits_reverse = model(example_text_reverse) # Shape batch x position x vocab\n",
    "example_logit_diff_reverse = get_logit_diff(example_logits_reverse)\n",
    "print(f\"Input text: {example_text}, John logit - Mary logit: {example_logit_diff.item()}\")\n",
    "print(f\"Input text: {example_text_reverse}, John logit - Mary logit: {example_logit_diff_reverse.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed torch.Size([17, 768])\n",
      "hook_pos_embed torch.Size([17, 768])\n",
      "blocks.0.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.0.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.0.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.0.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.0.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.0.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.0.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.0.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.0.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.0.hook_attn_out torch.Size([17, 768])\n",
      "blocks.0.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.0.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.0.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.0.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.0.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.0.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.0.hook_resid_post torch.Size([17, 768])\n",
      "blocks.1.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.1.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.1.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.1.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.1.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.1.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.1.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.1.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.1.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.1.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.1.hook_attn_out torch.Size([17, 768])\n",
      "blocks.1.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.1.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.1.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.1.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.1.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.1.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.1.hook_resid_post torch.Size([17, 768])\n",
      "blocks.2.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.2.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.2.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.2.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.2.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.2.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.2.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.2.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.2.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.2.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.2.hook_attn_out torch.Size([17, 768])\n",
      "blocks.2.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.2.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.2.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.2.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.2.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.2.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.2.hook_resid_post torch.Size([17, 768])\n",
      "blocks.3.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.3.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.3.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.3.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.3.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.3.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.3.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.3.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.3.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.3.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.3.hook_attn_out torch.Size([17, 768])\n",
      "blocks.3.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.3.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.3.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.3.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.3.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.3.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.3.hook_resid_post torch.Size([17, 768])\n",
      "blocks.4.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.4.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.4.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.4.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.4.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.4.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.4.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.4.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.4.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.4.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.4.hook_attn_out torch.Size([17, 768])\n",
      "blocks.4.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.4.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.4.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.4.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.4.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.4.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.4.hook_resid_post torch.Size([17, 768])\n",
      "blocks.5.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.5.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.5.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.5.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.5.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.5.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.5.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.5.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.5.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.5.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.5.hook_attn_out torch.Size([17, 768])\n",
      "blocks.5.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.5.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.5.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.5.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.5.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.5.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.5.hook_resid_post torch.Size([17, 768])\n",
      "blocks.6.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.6.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.6.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.6.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.6.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.6.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.6.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.6.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.6.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.6.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.6.hook_attn_out torch.Size([17, 768])\n",
      "blocks.6.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.6.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.6.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.6.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.6.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.6.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.6.hook_resid_post torch.Size([17, 768])\n",
      "blocks.7.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.7.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.7.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.7.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.7.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.7.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.7.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.7.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.7.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.7.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.7.hook_attn_out torch.Size([17, 768])\n",
      "blocks.7.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.7.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.7.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.7.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.7.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.7.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.7.hook_resid_post torch.Size([17, 768])\n",
      "blocks.8.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.8.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.8.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.8.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.8.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.8.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.8.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.8.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.8.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.8.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.8.hook_attn_out torch.Size([17, 768])\n",
      "blocks.8.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.8.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.8.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.8.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.8.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.8.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.8.hook_resid_post torch.Size([17, 768])\n",
      "blocks.9.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.9.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.9.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.9.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.9.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.9.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.9.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.9.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.9.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.9.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.9.hook_attn_out torch.Size([17, 768])\n",
      "blocks.9.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.9.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.9.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.9.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.9.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.9.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.9.hook_resid_post torch.Size([17, 768])\n",
      "blocks.10.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.10.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.10.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.10.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.10.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.10.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.10.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.10.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.10.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.10.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.10.hook_attn_out torch.Size([17, 768])\n",
      "blocks.10.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.10.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.10.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.10.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.10.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.10.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.10.hook_resid_post torch.Size([17, 768])\n",
      "blocks.11.hook_resid_pre torch.Size([17, 768])\n",
      "blocks.11.ln1.hook_scale torch.Size([17, 1])\n",
      "blocks.11.ln1.hook_normalized torch.Size([17, 768])\n",
      "blocks.11.attn.hook_q torch.Size([17, 12, 64])\n",
      "blocks.11.attn.hook_k torch.Size([17, 12, 64])\n",
      "blocks.11.attn.hook_v torch.Size([17, 12, 64])\n",
      "blocks.11.attn.hook_attn_scores torch.Size([12, 17, 17])\n",
      "blocks.11.attn.hook_pattern torch.Size([12, 17, 17])\n",
      "blocks.11.attn.hook_z torch.Size([17, 12, 64])\n",
      "blocks.11.attn.hook_result torch.Size([17, 12, 768])\n",
      "blocks.11.hook_attn_out torch.Size([17, 768])\n",
      "blocks.11.hook_resid_mid torch.Size([17, 768])\n",
      "blocks.11.ln2.hook_scale torch.Size([17, 1])\n",
      "blocks.11.ln2.hook_normalized torch.Size([17, 768])\n",
      "blocks.11.mlp.hook_pre torch.Size([17, 3072])\n",
      "blocks.11.mlp.hook_post torch.Size([17, 3072])\n",
      "blocks.11.hook_mlp_out torch.Size([17, 768])\n",
      "blocks.11.hook_resid_post torch.Size([17, 768])\n",
      "ln_final.hook_scale torch.Size([17, 1])\n",
      "ln_final.hook_normalized torch.Size([17, 768])\n"
     ]
    }
   ],
   "source": [
    "model.cfg.use_attn_result = True\n",
    "example_cache = {}\n",
    "model.cache_all(example_cache, remove_batch_dim=True)\n",
    "_ = model(example_text)\n",
    "model.reset_hooks()\n",
    "reverse_example_cache = {}\n",
    "model.cache_all(reverse_example_cache, remove_batch_dim=True)\n",
    "_ = model(example_text_reverse)\n",
    "model.reset_hooks()\n",
    "model.cfg.use_attn_result = False\n",
    "for act_name in example_cache:\n",
    "    print(act_name, example_cache[act_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input split into tokens: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shops', ',', ' Mary', ' handed', ' a', ' bottle', ' of', ' milk', ' to']\n",
      "Index of John token: 1757. Index of Mary token: 5335\n",
      "Input text: After John and Mary went to the shops, Mary handed a bottle of milk to, John logit - Mary logit: 4.0183610916137695\n",
      "Input text: After John and Mary went to the shops, John handed a bottle of milk to, John logit - Mary logit: -2.918598175048828\n"
     ]
    }
   ],
   "source": [
    "example_text = \"After John and Mary went to the shops, Mary handed a bottle of milk to\"\n",
    "example_text_reverse = \"After John and Mary went to the shops, John handed a bottle of milk to\"\n",
    "example_str_tokens = model.to_str_tokens(example_text, prepend_bos=True)\n",
    "\n",
    "print(\"Input split into tokens:\", example_str_tokens)\n",
    "\n",
    "\n",
    "john_index = model.tokenizer.encode(\" John\")[0]\n",
    "mary_index = model.tokenizer.encode(\" Mary\")[0]\n",
    "print(f\"Index of John token: {john_index}. Index of Mary token: {mary_index}\")\n",
    "\n",
    "def get_logit_diff(logits):\n",
    "    # Takes in a batch x position x vocab tensor of logits, and returns the difference between the John and Mary logit\n",
    "    return logits[0, -1, john_index] - logits[0, -1, mary_index]\n",
    "\n",
    "\n",
    "example_logits = model(example_text) # Shape batch x position x vocab\n",
    "example_logit_diff = get_logit_diff(example_logits)\n",
    "example_logits_reverse = model(example_text_reverse) # Shape batch x position x vocab\n",
    "example_logit_diff_reverse = get_logit_diff(example_logits_reverse)\n",
    "print(f\"Input text: {example_text}, John logit - Mary logit: {example_logit_diff.item()}\")\n",
    "print(f\"Input text: {example_text_reverse}, John logit - Mary logit: {example_logit_diff_reverse.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Input split into tokens: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' went', ' to', ' the', ' shops', ',', ' Mary', ' handed', ' a', ' bottle', ' of', ' milk', ' to']\n",
      "Input text: After John and Mary went to the shops, Mary handed a bottle of milk to, John logit - Mary logit: 4.0183610916137695\n",
      "Input text: After John and Mary went to the shops, John handed a bottle of milk to, John logit - Mary logit: -2.918598175048828\n",
      "1\n",
      "Input split into tokens: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' got', ' home', ',', ' Mary', ' handed', ' the', ' car', ' keys', ' to']\n",
      "Input text: After John and Mary got home, Mary handed the car keys to, John logit - Mary logit: 3.8062944412231445\n",
      "Input text: After John and Mary got home, John handed the car keys to, John logit - Mary logit: -2.6187286376953125\n",
      "2\n",
      "Input split into tokens: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' started', ' corresponding', ',', ' Mary', ' wrote', ' a', ' letter', ' to']\n",
      "Input text: After John and Mary started corresponding, Mary wrote a letter to, John logit - Mary logit: 3.131852149963379\n",
      "Input text: After John and Mary started corresponding, John wrote a letter to, John logit - Mary logit: -2.5299301147460938\n",
      "3\n",
      "Input split into tokens: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' fought', ',', ' Mary', ' apologized', ' to']\n",
      "Input text: After John and Mary fought, Mary apologized to, John logit - Mary logit: 3.8220386505126953\n",
      "Input text: After John and Mary fought, John apologized to, John logit - Mary logit: -2.3657798767089844\n",
      "4\n",
      "Input split into tokens: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' shared', ' dinner', ',', ' Mary', ' thanked']\n",
      "Input text: After John and Mary shared dinner, Mary thanked, John logit - Mary logit: 3.1394033432006836\n",
      "Input text: After John and Mary shared dinner, John thanked, John logit - Mary logit: -2.1906814575195312\n"
     ]
    }
   ],
   "source": [
    "person_1 = \"John\"\n",
    "person_2 = \"Mary\"\n",
    "\n",
    "\n",
    "example_texts = [f\"After {person_1} and {person_2} went to the shops, {person_2} handed a bottle of milk to\",\n",
    "                 f\"After {person_1} and {person_2} got home, {person_2} handed the car keys to\", \n",
    "                 f\"After {person_1} and {person_2} started corresponding, {person_2} wrote a letter to\", \n",
    "                 f\"After {person_1} and {person_2} fought, {person_2} apologized to\",\n",
    "                 f\"After {person_1} and {person_2} shared dinner, {person_2} thanked\"] \n",
    "\n",
    "\n",
    "example_text_reverses = [f\"After {person_1} and {person_2} went to the shops, {person_1} handed a bottle of milk to\",\n",
    "                            f\"After {person_1} and {person_2} got home, {person_1} handed the car keys to\",\n",
    "                            f\"After {person_1} and {person_2} started corresponding, {person_1} wrote a letter to\",\n",
    "                            f\"After {person_1} and {person_2} fought, {person_1} apologized to\",\n",
    "                            f\"After {person_1} and {person_2} shared dinner, {person_1} thanked\"]\n",
    "\n",
    "for i in range(len(example_texts)):\n",
    "    print(i)\n",
    "    example_text = example_texts[i]\n",
    "    example_text_reverse = example_text_reverses[i]\n",
    "    example_str_tokens = model.to_str_tokens(example_text, prepend_bos=True)\n",
    "    print(\"Input split into tokens:\", example_str_tokens)\n",
    "    example_logits = model(example_text) # Shape batch x position x vocab\n",
    "    example_logit_diff = get_logit_diff(example_logits)\n",
    "    example_logits_reverse = model(example_text_reverse) # Shape batch x position x vocab\n",
    "    example_logit_diff_reverse = get_logit_diff(example_logits_reverse)\n",
    "    print(f\"Input text: {example_text}, John logit - Mary logit: {example_logit_diff.item()}\")\n",
    "    print(f\"Input text: {example_text_reverse}, John logit - Mary logit: {example_logit_diff_reverse.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.14.0.min.js\"></script>                <div id=\"7a39f550-feaa-4c1d-b929-652dc626665f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7a39f550-feaa-4c1d-b929-652dc626665f\")) {                    Plotly.newPlot(                        \"7a39f550-feaa-4c1d-b929-652dc626665f\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"<|endoftext|>_0\",\"After_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" shops_8\",\",_9\",\" Mary_10\",\" handed_11\",\" a_12\",\" bottle_13\",\" of_14\",\" milk_15\",\" to_16\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62993234,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.60811484,0.026041687,0.025486676,0.048764944,0.017661456,0.016864125,0.008387624],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6352728,0.036746524,0.019831693,0.04159214,0.015595788,0.017631656,0.008920598],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.627202,0.07253669,0.03977043,0.038641687,0.02440399,0.018600434,0.010443883],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6183596,0.11283052,0.05405244,0.03861271,0.029498769,0.02561242,0.018638816],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.60401124,0.18503395,0.067866035,0.043271977,0.029527303,0.02699842,0.019516308],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59174377,0.15873107,0.067751296,0.04186743,0.03221071,0.030080156,0.028768573],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6023905,0.19331552,0.09065798,0.04364512,0.037367947,0.034796704,0.045123164],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6112048,0.25800267,0.09207413,0.045728438,0.03688472,0.03348607,0.25568435],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5465474,0.29079044,0.08300333,0.048130292,0.046465024,0.04377287,0.39958096],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46823967,0.28684443,0.072796136,0.04587928,0.051355164,0.041617844,0.52911395],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35248265,0.21053873,0.055907775,0.055284806,0.055467248,0.053709444,0.32914445]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Norm of difference in residual stream\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7a39f550-feaa-4c1d-b929-652dc626665f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_length = len(model.to_tokens(example_text, prepend_bos=True)[0])\n",
    "norm_difference = torch.zeros(model.cfg.n_layers, example_length)\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    example_resid = example_cache[f\"blocks.{layer}.hook_resid_pre\"]\n",
    "    reverse_example_resid = reverse_example_cache[f\"blocks.{layer}.hook_resid_pre\"]\n",
    "    resid_diff = (example_resid - reverse_example_resid)\n",
    "    # Compare the activations, normalising by the average size of the original activations\n",
    "    norm_difference[layer] = resid_diff.norm(dim=-1)/(example_resid.norm(dim=-1) * reverse_example_resid.norm(dim=-1)).sqrt()\n",
    "\n",
    "# I need to make the labels {token}_{index} so they're all unique because Plotly gets confused if given duplicate labels for imshow\n",
    "imshow(norm_difference, yaxis='Layer', x=[f\"{token}_{c}\" for c, token in enumerate(example_str_tokens)], title='Norm of difference in residual stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.14.0.min.js\"></script>                <div id=\"14830cc9-998b-4f22-a6c2-542136aadcbb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"14830cc9-998b-4f22-a6c2-542136aadcbb\")) {                    Plotly.newPlot(                        \"14830cc9-998b-4f22-a6c2-542136aadcbb\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4535058,0.034285977,0.048599776,0.06404264,0.03313403,0.020646013,0.015604805],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5588978,0.26403052,0.14895725,0.16007842,0.11577281,0.11527238,0.08401265],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35655665,0.361095,0.20158605,0.14228094,0.093679294,0.11041902,0.054836188],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68391144,0.53568256,0.17396384,0.17321834,0.11258411,0.1734908,0.07895984],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5478773,0.7677814,0.21375674,0.110781595,0.091021374,0.1051605,0.10193648],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7981645,0.28917176,0.20333287,0.13660589,0.081576906,0.15603721,0.11507728],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6781354,0.48790568,0.35254994,0.18064506,0.16826466,0.15456215,0.21910743],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9352977,0.9461771,0.24149826,0.28348708,0.14005132,0.108223274,1.0213399],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2689167,0.7215724,0.18951325,0.19066589,0.18142554,0.17245436,0.7574761],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.20786439,0.5289351,0.29005224,0.1687535,0.22708742,0.11773627,1.0214155],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11731776,0.3335908,0.10932585,0.41229045,0.39400622,0.22916949,0.88976383],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.040725246,0.053640738,0.023286942,0.039500587,0.021730745,0.029234102,0.12820475]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Norm of difference in attn_out\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('14830cc9-998b-4f22-a6c2-542136aadcbb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_length = len(model.to_tokens(example_text, prepend_bos=True)[0])\n",
    "norm_difference = torch.zeros(model.cfg.n_layers, example_length)\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    example_attn_out = example_cache[f\"blocks.{layer}.hook_attn_out\"]\n",
    "    reverse_example_attn_out = reverse_example_cache[f\"blocks.{layer}.hook_attn_out\"]\n",
    "    attn_out_diff = (example_attn_out - reverse_example_attn_out)\n",
    "    # Compare the activations, normalising by the average size of the original activations\n",
    "    norm_difference[layer] = attn_out_diff.norm(dim=-1)/(example_attn_out.norm(dim=-1) * reverse_example_attn_out.norm(dim=-1)).sqrt()\n",
    "\n",
    "# I need to make the labels {token}_{index} so they're all unique because Plotly gets confused if given duplicate labels for imshow\n",
    "imshow(norm_difference, yaxis='Layer', title='Norm of difference in attn_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('arena')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b7e6b471291409f54dffbfbdfeccd6f1f2b5fb302e7acf62f723cf276419720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
