{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephbloom/miniforge3/envs/arena/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/josephbloom/miniforge3/envs/arena/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowExxb\n",
      "  Referenced from: <D9493EF5-8DAB-3A5D-85D5-684F04544B84> /Users/josephbloom/miniforge3/envs/arena/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <52337463-FA04-3610-8715-68C586545714> /Users/josephbloom/miniforge3/envs/arena/lib/python3.10/site-packages/torch/lib/libc10.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, total params = 3576704\n",
      "Model 2, total params = 3576704\n",
      "All parameter counts match!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ba426_row0_col2, #T_ba426_row0_col3 {\n",
       "  background-color: #c2df23;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ba426_row1_col2, #T_ba426_row1_col3, #T_ba426_row2_col2, #T_ba426_row2_col3 {\n",
       "  background-color: #414487;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ba426_row3_col2, #T_ba426_row3_col3 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ba426_row4_col2, #T_ba426_row4_col3, #T_ba426_row5_col2, #T_ba426_row5_col3 {\n",
       "  background-color: #472f7d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ba426_row6_col2, #T_ba426_row6_col3 {\n",
       "  background-color: #a5db36;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ba426_row7_col2, #T_ba426_row7_col3, #T_ba426_row8_col2, #T_ba426_row8_col3 {\n",
       "  background-color: #481a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ba426_row9_col2, #T_ba426_row9_col3 {\n",
       "  background-color: #54c568;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ba426_row10_col2, #T_ba426_row10_col3, #T_ba426_row11_col2, #T_ba426_row11_col3 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ba426_row12_col2, #T_ba426_row12_col3 {\n",
       "  background-color: #2c718e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ba426\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ba426_level0_col0\" class=\"col_heading level0 col0\" >name_1</th>\n",
       "      <th id=\"T_ba426_level0_col1\" class=\"col_heading level0 col1\" >shape_1</th>\n",
       "      <th id=\"T_ba426_level0_col2\" class=\"col_heading level0 col2\" >num_params_1</th>\n",
       "      <th id=\"T_ba426_level0_col3\" class=\"col_heading level0 col3\" >num_params_2</th>\n",
       "      <th id=\"T_ba426_level0_col4\" class=\"col_heading level0 col4\" >shape_2</th>\n",
       "      <th id=\"T_ba426_level0_col5\" class=\"col_heading level0 col5\" >name_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ba426_row0_col0\" class=\"data row0 col0\" >project_and_reshape.0.weight</td>\n",
       "      <td id=\"T_ba426_row0_col1\" class=\"data row0 col1\" >(8192, 100)</td>\n",
       "      <td id=\"T_ba426_row0_col2\" class=\"data row0 col2\" >819200</td>\n",
       "      <td id=\"T_ba426_row0_col3\" class=\"data row0 col3\" >819200</td>\n",
       "      <td id=\"T_ba426_row0_col4\" class=\"data row0 col4\" >(8192, 100)</td>\n",
       "      <td id=\"T_ba426_row0_col5\" class=\"data row0 col5\" >project_and_reshape.0.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ba426_row1_col0\" class=\"data row1 col0\" >project_and_reshape.2.weight</td>\n",
       "      <td id=\"T_ba426_row1_col1\" class=\"data row1 col1\" >(512,)</td>\n",
       "      <td id=\"T_ba426_row1_col2\" class=\"data row1 col2\" >512</td>\n",
       "      <td id=\"T_ba426_row1_col3\" class=\"data row1 col3\" >512</td>\n",
       "      <td id=\"T_ba426_row1_col4\" class=\"data row1 col4\" >(512,)</td>\n",
       "      <td id=\"T_ba426_row1_col5\" class=\"data row1 col5\" >project_and_reshape.2.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ba426_row2_col0\" class=\"data row2 col0\" >project_and_reshape.2.bias</td>\n",
       "      <td id=\"T_ba426_row2_col1\" class=\"data row2 col1\" >(512,)</td>\n",
       "      <td id=\"T_ba426_row2_col2\" class=\"data row2 col2\" >512</td>\n",
       "      <td id=\"T_ba426_row2_col3\" class=\"data row2 col3\" >512</td>\n",
       "      <td id=\"T_ba426_row2_col4\" class=\"data row2 col4\" >(512,)</td>\n",
       "      <td id=\"T_ba426_row2_col5\" class=\"data row2 col5\" >project_and_reshape.2.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ba426_row3_col0\" class=\"data row3 col0\" >layers.0.conv.weight</td>\n",
       "      <td id=\"T_ba426_row3_col1\" class=\"data row3 col1\" >(512, 256, 4, 4)</td>\n",
       "      <td id=\"T_ba426_row3_col2\" class=\"data row3 col2\" >2097152</td>\n",
       "      <td id=\"T_ba426_row3_col3\" class=\"data row3 col3\" >2097152</td>\n",
       "      <td id=\"T_ba426_row3_col4\" class=\"data row3 col4\" >(512, 256, 4, 4)</td>\n",
       "      <td id=\"T_ba426_row3_col5\" class=\"data row3 col5\" >layers.0.0.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ba426_row4_col0\" class=\"data row4 col0\" >layers.0.bn.weight</td>\n",
       "      <td id=\"T_ba426_row4_col1\" class=\"data row4 col1\" >(256,)</td>\n",
       "      <td id=\"T_ba426_row4_col2\" class=\"data row4 col2\" >256</td>\n",
       "      <td id=\"T_ba426_row4_col3\" class=\"data row4 col3\" >256</td>\n",
       "      <td id=\"T_ba426_row4_col4\" class=\"data row4 col4\" >(256,)</td>\n",
       "      <td id=\"T_ba426_row4_col5\" class=\"data row4 col5\" >layers.0.1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ba426_row5_col0\" class=\"data row5 col0\" >layers.0.bn.bias</td>\n",
       "      <td id=\"T_ba426_row5_col1\" class=\"data row5 col1\" >(256,)</td>\n",
       "      <td id=\"T_ba426_row5_col2\" class=\"data row5 col2\" >256</td>\n",
       "      <td id=\"T_ba426_row5_col3\" class=\"data row5 col3\" >256</td>\n",
       "      <td id=\"T_ba426_row5_col4\" class=\"data row5 col4\" >(256,)</td>\n",
       "      <td id=\"T_ba426_row5_col5\" class=\"data row5 col5\" >layers.0.1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ba426_row6_col0\" class=\"data row6 col0\" >layers.1.conv.weight</td>\n",
       "      <td id=\"T_ba426_row6_col1\" class=\"data row6 col1\" >(256, 128, 4, 4)</td>\n",
       "      <td id=\"T_ba426_row6_col2\" class=\"data row6 col2\" >524288</td>\n",
       "      <td id=\"T_ba426_row6_col3\" class=\"data row6 col3\" >524288</td>\n",
       "      <td id=\"T_ba426_row6_col4\" class=\"data row6 col4\" >(256, 128, 4, 4)</td>\n",
       "      <td id=\"T_ba426_row6_col5\" class=\"data row6 col5\" >layers.1.0.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ba426_row7_col0\" class=\"data row7 col0\" >layers.1.bn.weight</td>\n",
       "      <td id=\"T_ba426_row7_col1\" class=\"data row7 col1\" >(128,)</td>\n",
       "      <td id=\"T_ba426_row7_col2\" class=\"data row7 col2\" >128</td>\n",
       "      <td id=\"T_ba426_row7_col3\" class=\"data row7 col3\" >128</td>\n",
       "      <td id=\"T_ba426_row7_col4\" class=\"data row7 col4\" >(128,)</td>\n",
       "      <td id=\"T_ba426_row7_col5\" class=\"data row7 col5\" >layers.1.1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ba426_row8_col0\" class=\"data row8 col0\" >layers.1.bn.bias</td>\n",
       "      <td id=\"T_ba426_row8_col1\" class=\"data row8 col1\" >(128,)</td>\n",
       "      <td id=\"T_ba426_row8_col2\" class=\"data row8 col2\" >128</td>\n",
       "      <td id=\"T_ba426_row8_col3\" class=\"data row8 col3\" >128</td>\n",
       "      <td id=\"T_ba426_row8_col4\" class=\"data row8 col4\" >(128,)</td>\n",
       "      <td id=\"T_ba426_row8_col5\" class=\"data row8 col5\" >layers.1.1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ba426_row9_col0\" class=\"data row9 col0\" >layers.2.conv.weight</td>\n",
       "      <td id=\"T_ba426_row9_col1\" class=\"data row9 col1\" >(128, 64, 4, 4)</td>\n",
       "      <td id=\"T_ba426_row9_col2\" class=\"data row9 col2\" >131072</td>\n",
       "      <td id=\"T_ba426_row9_col3\" class=\"data row9 col3\" >131072</td>\n",
       "      <td id=\"T_ba426_row9_col4\" class=\"data row9 col4\" >(128, 64, 4, 4)</td>\n",
       "      <td id=\"T_ba426_row9_col5\" class=\"data row9 col5\" >layers.2.0.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ba426_row10_col0\" class=\"data row10 col0\" >layers.2.bn.weight</td>\n",
       "      <td id=\"T_ba426_row10_col1\" class=\"data row10 col1\" >(64,)</td>\n",
       "      <td id=\"T_ba426_row10_col2\" class=\"data row10 col2\" >64</td>\n",
       "      <td id=\"T_ba426_row10_col3\" class=\"data row10 col3\" >64</td>\n",
       "      <td id=\"T_ba426_row10_col4\" class=\"data row10 col4\" >(64,)</td>\n",
       "      <td id=\"T_ba426_row10_col5\" class=\"data row10 col5\" >layers.2.1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ba426_row11_col0\" class=\"data row11 col0\" >layers.2.bn.bias</td>\n",
       "      <td id=\"T_ba426_row11_col1\" class=\"data row11 col1\" >(64,)</td>\n",
       "      <td id=\"T_ba426_row11_col2\" class=\"data row11 col2\" >64</td>\n",
       "      <td id=\"T_ba426_row11_col3\" class=\"data row11 col3\" >64</td>\n",
       "      <td id=\"T_ba426_row11_col4\" class=\"data row11 col4\" >(64,)</td>\n",
       "      <td id=\"T_ba426_row11_col5\" class=\"data row11 col5\" >layers.2.1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ba426_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ba426_row12_col0\" class=\"data row12 col0\" >layers.3.conv.weight</td>\n",
       "      <td id=\"T_ba426_row12_col1\" class=\"data row12 col1\" >(64, 3, 4, 4)</td>\n",
       "      <td id=\"T_ba426_row12_col2\" class=\"data row12 col2\" >3072</td>\n",
       "      <td id=\"T_ba426_row12_col3\" class=\"data row12 col3\" >3072</td>\n",
       "      <td id=\"T_ba426_row12_col4\" class=\"data row12 col4\" >(64, 3, 4, 4)</td>\n",
       "      <td id=\"T_ba426_row12_col5\" class=\"data row12 col5\" >layers.3.0.weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a63fa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from w5d1_solutions import celeb_DCGAN, celeb_mini_DCGAN\n",
    "import w5d1_utils\n",
    "from GAN_implementation.models import Generator, initialize_weights_generator\n",
    "\n",
    "my_Generator = Generator(100, 64, 3, 512, 4)\n",
    "initialize_weights_generator(my_Generator)\n",
    "w5d1_utils.print_param_count(my_Generator, celeb_mini_DCGAN.netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, total params = 2766528\n",
      "Model 2, total params = 2766528\n",
      "All parameter counts match!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_89651_row0_col2, #T_89651_row0_col3 {\n",
       "  background-color: #2c718e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89651_row1_col2, #T_89651_row1_col3 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89651_row2_col2, #T_89651_row2_col3 {\n",
       "  background-color: #54c568;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_89651_row3_col2, #T_89651_row3_col3, #T_89651_row4_col2, #T_89651_row4_col3, #T_89651_row5_col2, #T_89651_row5_col3 {\n",
       "  background-color: #481a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89651_row6_col2, #T_89651_row6_col3 {\n",
       "  background-color: #a5db36;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_89651_row7_col2, #T_89651_row7_col3, #T_89651_row8_col2, #T_89651_row8_col3, #T_89651_row9_col2, #T_89651_row9_col3 {\n",
       "  background-color: #472f7d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89651_row10_col2, #T_89651_row10_col3 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_89651_row11_col2, #T_89651_row11_col3, #T_89651_row12_col2, #T_89651_row12_col3, #T_89651_row13_col2, #T_89651_row13_col3 {\n",
       "  background-color: #414487;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89651_row14_col2, #T_89651_row14_col3 {\n",
       "  background-color: #23888e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_89651\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_89651_level0_col0\" class=\"col_heading level0 col0\" >name_1</th>\n",
       "      <th id=\"T_89651_level0_col1\" class=\"col_heading level0 col1\" >shape_1</th>\n",
       "      <th id=\"T_89651_level0_col2\" class=\"col_heading level0 col2\" >num_params_1</th>\n",
       "      <th id=\"T_89651_level0_col3\" class=\"col_heading level0 col3\" >num_params_2</th>\n",
       "      <th id=\"T_89651_level0_col4\" class=\"col_heading level0 col4\" >shape_2</th>\n",
       "      <th id=\"T_89651_level0_col5\" class=\"col_heading level0 col5\" >name_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_89651_row0_col0\" class=\"data row0 col0\" >layers.0.conv.weight</td>\n",
       "      <td id=\"T_89651_row0_col1\" class=\"data row0 col1\" >(64, 3, 4, 4)</td>\n",
       "      <td id=\"T_89651_row0_col2\" class=\"data row0 col2\" >3072</td>\n",
       "      <td id=\"T_89651_row0_col3\" class=\"data row0 col3\" >3072</td>\n",
       "      <td id=\"T_89651_row0_col4\" class=\"data row0 col4\" >(64, 3, 4, 4)</td>\n",
       "      <td id=\"T_89651_row0_col5\" class=\"data row0 col5\" >layers.0.0.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_89651_row1_col0\" class=\"data row1 col0\" >layers.0.conv.bias</td>\n",
       "      <td id=\"T_89651_row1_col1\" class=\"data row1 col1\" >(64,)</td>\n",
       "      <td id=\"T_89651_row1_col2\" class=\"data row1 col2\" >64</td>\n",
       "      <td id=\"T_89651_row1_col3\" class=\"data row1 col3\" >64</td>\n",
       "      <td id=\"T_89651_row1_col4\" class=\"data row1 col4\" >(64,)</td>\n",
       "      <td id=\"T_89651_row1_col5\" class=\"data row1 col5\" >layers.0.0.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_89651_row2_col0\" class=\"data row2 col0\" >layers.1.conv.weight</td>\n",
       "      <td id=\"T_89651_row2_col1\" class=\"data row2 col1\" >(128, 64, 4, 4)</td>\n",
       "      <td id=\"T_89651_row2_col2\" class=\"data row2 col2\" >131072</td>\n",
       "      <td id=\"T_89651_row2_col3\" class=\"data row2 col3\" >131072</td>\n",
       "      <td id=\"T_89651_row2_col4\" class=\"data row2 col4\" >(128, 64, 4, 4)</td>\n",
       "      <td id=\"T_89651_row2_col5\" class=\"data row2 col5\" >layers.1.0.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_89651_row3_col0\" class=\"data row3 col0\" >layers.1.conv.bias</td>\n",
       "      <td id=\"T_89651_row3_col1\" class=\"data row3 col1\" >(128,)</td>\n",
       "      <td id=\"T_89651_row3_col2\" class=\"data row3 col2\" >128</td>\n",
       "      <td id=\"T_89651_row3_col3\" class=\"data row3 col3\" >128</td>\n",
       "      <td id=\"T_89651_row3_col4\" class=\"data row3 col4\" >(128,)</td>\n",
       "      <td id=\"T_89651_row3_col5\" class=\"data row3 col5\" >layers.1.0.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_89651_row4_col0\" class=\"data row4 col0\" >layers.1.bn.weight</td>\n",
       "      <td id=\"T_89651_row4_col1\" class=\"data row4 col1\" >(128,)</td>\n",
       "      <td id=\"T_89651_row4_col2\" class=\"data row4 col2\" >128</td>\n",
       "      <td id=\"T_89651_row4_col3\" class=\"data row4 col3\" >128</td>\n",
       "      <td id=\"T_89651_row4_col4\" class=\"data row4 col4\" >(128,)</td>\n",
       "      <td id=\"T_89651_row4_col5\" class=\"data row4 col5\" >layers.1.1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_89651_row5_col0\" class=\"data row5 col0\" >layers.1.bn.bias</td>\n",
       "      <td id=\"T_89651_row5_col1\" class=\"data row5 col1\" >(128,)</td>\n",
       "      <td id=\"T_89651_row5_col2\" class=\"data row5 col2\" >128</td>\n",
       "      <td id=\"T_89651_row5_col3\" class=\"data row5 col3\" >128</td>\n",
       "      <td id=\"T_89651_row5_col4\" class=\"data row5 col4\" >(128,)</td>\n",
       "      <td id=\"T_89651_row5_col5\" class=\"data row5 col5\" >layers.1.1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_89651_row6_col0\" class=\"data row6 col0\" >layers.2.conv.weight</td>\n",
       "      <td id=\"T_89651_row6_col1\" class=\"data row6 col1\" >(256, 128, 4, 4)</td>\n",
       "      <td id=\"T_89651_row6_col2\" class=\"data row6 col2\" >524288</td>\n",
       "      <td id=\"T_89651_row6_col3\" class=\"data row6 col3\" >524288</td>\n",
       "      <td id=\"T_89651_row6_col4\" class=\"data row6 col4\" >(256, 128, 4, 4)</td>\n",
       "      <td id=\"T_89651_row6_col5\" class=\"data row6 col5\" >layers.2.0.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_89651_row7_col0\" class=\"data row7 col0\" >layers.2.conv.bias</td>\n",
       "      <td id=\"T_89651_row7_col1\" class=\"data row7 col1\" >(256,)</td>\n",
       "      <td id=\"T_89651_row7_col2\" class=\"data row7 col2\" >256</td>\n",
       "      <td id=\"T_89651_row7_col3\" class=\"data row7 col3\" >256</td>\n",
       "      <td id=\"T_89651_row7_col4\" class=\"data row7 col4\" >(256,)</td>\n",
       "      <td id=\"T_89651_row7_col5\" class=\"data row7 col5\" >layers.2.0.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_89651_row8_col0\" class=\"data row8 col0\" >layers.2.bn.weight</td>\n",
       "      <td id=\"T_89651_row8_col1\" class=\"data row8 col1\" >(256,)</td>\n",
       "      <td id=\"T_89651_row8_col2\" class=\"data row8 col2\" >256</td>\n",
       "      <td id=\"T_89651_row8_col3\" class=\"data row8 col3\" >256</td>\n",
       "      <td id=\"T_89651_row8_col4\" class=\"data row8 col4\" >(256,)</td>\n",
       "      <td id=\"T_89651_row8_col5\" class=\"data row8 col5\" >layers.2.1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_89651_row9_col0\" class=\"data row9 col0\" >layers.2.bn.bias</td>\n",
       "      <td id=\"T_89651_row9_col1\" class=\"data row9 col1\" >(256,)</td>\n",
       "      <td id=\"T_89651_row9_col2\" class=\"data row9 col2\" >256</td>\n",
       "      <td id=\"T_89651_row9_col3\" class=\"data row9 col3\" >256</td>\n",
       "      <td id=\"T_89651_row9_col4\" class=\"data row9 col4\" >(256,)</td>\n",
       "      <td id=\"T_89651_row9_col5\" class=\"data row9 col5\" >layers.2.1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_89651_row10_col0\" class=\"data row10 col0\" >layers.3.conv.weight</td>\n",
       "      <td id=\"T_89651_row10_col1\" class=\"data row10 col1\" >(512, 256, 4, 4)</td>\n",
       "      <td id=\"T_89651_row10_col2\" class=\"data row10 col2\" >2097152</td>\n",
       "      <td id=\"T_89651_row10_col3\" class=\"data row10 col3\" >2097152</td>\n",
       "      <td id=\"T_89651_row10_col4\" class=\"data row10 col4\" >(512, 256, 4, 4)</td>\n",
       "      <td id=\"T_89651_row10_col5\" class=\"data row10 col5\" >layers.3.0.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_89651_row11_col0\" class=\"data row11 col0\" >layers.3.conv.bias</td>\n",
       "      <td id=\"T_89651_row11_col1\" class=\"data row11 col1\" >(512,)</td>\n",
       "      <td id=\"T_89651_row11_col2\" class=\"data row11 col2\" >512</td>\n",
       "      <td id=\"T_89651_row11_col3\" class=\"data row11 col3\" >512</td>\n",
       "      <td id=\"T_89651_row11_col4\" class=\"data row11 col4\" >(512,)</td>\n",
       "      <td id=\"T_89651_row11_col5\" class=\"data row11 col5\" >layers.3.0.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_89651_row12_col0\" class=\"data row12 col0\" >layers.3.bn.weight</td>\n",
       "      <td id=\"T_89651_row12_col1\" class=\"data row12 col1\" >(512,)</td>\n",
       "      <td id=\"T_89651_row12_col2\" class=\"data row12 col2\" >512</td>\n",
       "      <td id=\"T_89651_row12_col3\" class=\"data row12 col3\" >512</td>\n",
       "      <td id=\"T_89651_row12_col4\" class=\"data row12 col4\" >(512,)</td>\n",
       "      <td id=\"T_89651_row12_col5\" class=\"data row12 col5\" >layers.3.1.weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_89651_row13_col0\" class=\"data row13 col0\" >layers.3.bn.bias</td>\n",
       "      <td id=\"T_89651_row13_col1\" class=\"data row13 col1\" >(512,)</td>\n",
       "      <td id=\"T_89651_row13_col2\" class=\"data row13 col2\" >512</td>\n",
       "      <td id=\"T_89651_row13_col3\" class=\"data row13 col3\" >512</td>\n",
       "      <td id=\"T_89651_row13_col4\" class=\"data row13 col4\" >(512,)</td>\n",
       "      <td id=\"T_89651_row13_col5\" class=\"data row13 col5\" >layers.3.1.bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89651_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_89651_row14_col0\" class=\"data row14 col0\" >linear.weight</td>\n",
       "      <td id=\"T_89651_row14_col1\" class=\"data row14 col1\" >(1, 8192)</td>\n",
       "      <td id=\"T_89651_row14_col2\" class=\"data row14 col2\" >8192</td>\n",
       "      <td id=\"T_89651_row14_col3\" class=\"data row14 col3\" >8192</td>\n",
       "      <td id=\"T_89651_row14_col4\" class=\"data row14 col4\" >(1, 8192)</td>\n",
       "      <td id=\"T_89651_row14_col5\" class=\"data row14 col5\" >classifier.1.weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15e73aad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from GAN_implementation.models import Discriminator\n",
    "my_Discriminator = Discriminator(64, 3, 512, 4)\n",
    "w5d1_utils.print_param_count(my_Discriminator, celeb_mini_DCGAN.netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from GAN_implementation.layers import Conv2d, ConvTranspose2d\n",
    "def initialize_weights_discriminator(model: nn.Module) -> None:\n",
    "    for i in model.modules():\n",
    "        if isinstance(i, Conv2d):\n",
    "            nn.init.normal_(i.weight, 0.0, 0.02)\n",
    "            if i.bias is not None:\n",
    "                nn.init.constant_(i.bias, 0)\n",
    "        elif isinstance(i, nn.BatchNorm2d):\n",
    "            nn.init.normal_(i.weight, 1.0, 0.02)\n",
    "            nn.init.constant_(i.bias, 0)\n",
    "        \n",
    "\n",
    "initialize_weights_discriminator(my_Discriminator)\n",
    "\n",
    "import torch.nn as nn\n",
    "def initialize_weights_generator(model) -> None:\n",
    "    for i in model.modules():\n",
    "        if isinstance(i, ConvTranspose2d):\n",
    "            nn.init.normal_(i.weight, 0.0, 0.02)\n",
    "            if i.bias is not None:\n",
    "                nn.init.constant_(i.bias, 0)\n",
    "        elif isinstance(i, nn.BatchNorm2d):\n",
    "            nn.init.normal_(i.weight, 1.0, 0.02)\n",
    "            nn.init.constant_(i.bias, 0)\n",
    "\n",
    "initialize_weights_generator(my_Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce86fa5196b4eb48c1e0ba8502dc4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12663 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [75], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m discriminator_optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(my_Discriminator\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.0002\u001b[39m, betas\u001b[39m=\u001b[39m(\u001b[39m0.5\u001b[39m,\u001b[39m0.999\u001b[39m))\n\u001b[1;32m     99\u001b[0m generator_optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(my_Generator\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.0002\u001b[39m, betas\u001b[39m=\u001b[39m(\u001b[39m0.5\u001b[39m,\u001b[39m0.999\u001b[39m))\n\u001b[0;32m--> 101\u001b[0m my_Generator, my_Discriminator \u001b[39m=\u001b[39m train_generator_discriminator(\n\u001b[1;32m    102\u001b[0m     my_Generator,\n\u001b[1;32m    103\u001b[0m     my_Discriminator,\n\u001b[1;32m    104\u001b[0m     generator_optimizer,\n\u001b[1;32m    105\u001b[0m     discriminator_optimizer,\n\u001b[1;32m    106\u001b[0m     trainloader,\n\u001b[1;32m    107\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m    108\u001b[0m     max_epoch_duration\u001b[39m=\u001b[39;49m\u001b[39m60\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m60\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m    109\u001b[0m     log_netG_output_interval\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m    110\u001b[0m     use_wandb\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    111\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    112\u001b[0m )\n",
      "Cell \u001b[0;32mIn [75], line 42\u001b[0m, in \u001b[0;36mtrain_generator_discriminator\u001b[0;34m(netG, netD, optG, optD, trainloader, epochs, max_epoch_duration, log_netG_output_interval, use_wandb, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m output \u001b[39m=\u001b[39m netD(real_images)\n\u001b[1;32m     41\u001b[0m errD_real \u001b[39m=\u001b[39m criterion(output\u001b[39m.\u001b[39mflatten(), label)\n\u001b[0;32m---> 42\u001b[0m errD_real\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     43\u001b[0m D_x \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     45\u001b[0m \u001b[39m# 1B. Train on fake\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/arena/lib/python3.10/site-packages/torch/_tensor.py:504\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    495\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    496\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    497\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    503\u001b[0m     )\n\u001b[0;32m--> 504\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    505\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    506\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/arena/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from typing import Optional, Union\n",
    "from torch import optim\n",
    "import time \n",
    "import torch as t\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "\n",
    "def train_generator_discriminator(\n",
    "    netG: Generator, \n",
    "    netD: Discriminator, \n",
    "    optG,\n",
    "    optD,\n",
    "    trainloader,\n",
    "    epochs: int,\n",
    "    max_epoch_duration: Optional[Union[int, float]] = None,           # Each epoch terminates after this many seconds\n",
    "    log_netG_output_interval: Optional[Union[int, float]] = None,     # Generator output is logged at this frequency\n",
    "    use_wandb: bool = True,\n",
    "    device: str = \"cpu\"):\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    fixed_noise = t.randn(64, 100, device=device)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.init(project=\"GAN_implementation\", entity=\"arena-ldn\")\n",
    "        wandb.watch(netG, log=\"all\")\n",
    "        wandb.watch(netD, log=\"all\")\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(enumerate(trainloader, 0), total=len(trainloader))\n",
    "        for i, data in pbar:\n",
    "            # 1. Train the discriminator on real+fake\n",
    "            netD.zero_grad()\n",
    "            # 1A. Train on real\n",
    "            real_images = data[0]\n",
    "            batch_size = real_images.size(0)\n",
    "            label = t.full((batch_size,), 1, dtype=t.float32)\n",
    "            output = netD(real_images)\n",
    "            errD_real = criterion(output.flatten(), label)\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            # 1B. Train on fake\n",
    "            noise = t.randn(batch_size, 100, device=device)\n",
    "            fake = netG(noise)\n",
    "            label.fill_(0)\n",
    "            output = netD(fake.detach())\n",
    "            errD_fake = criterion(output.flatten(), label)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            errD = errD_real + errD_fake\n",
    "            optD.step()\n",
    "\n",
    "            # 2. Train the generator on the discriminator's error\n",
    "            netG.zero_grad()\n",
    "            label.fill_(1)\n",
    "            output = netD(fake)\n",
    "            errG = criterion(output.flatten(), label)\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            optG.step()\n",
    "\n",
    "            # 3. Log metrics\n",
    "            pbar.set_description(f\"Epoch: {epoch}, Iteration: {i}, D(x): {D_x:.2f}, D(G(z)): {D_G_z1:.2f}/{D_G_z2:.2f}, D loss: {errD.item():.2f}, G loss: {errG.item():.2f}\")\n",
    "\n",
    "            if i % log_netG_output_interval == 0:\n",
    "                # print(f\"Epoch: {epoch}, Iteration: {i}, D(x): {D_x:.2f}, D(G(z)): {D_G_z1:.2f}/{D_G_z2:.2f}, D loss: {errD.item():.2f}, G loss: {errG.item():.2f}\")\n",
    "                if use_wandb:\n",
    "                    wandb.log({\n",
    "                        \"D(x)\": D_x,\n",
    "                        \"D(G(z))\": D_G_z1,\n",
    "                        \"D(G(z))\": D_G_z2,\n",
    "                        \"D loss\": errD.item(),\n",
    "                        \"G loss\": errG.item()\n",
    "                    })\n",
    "            \n",
    "            if use_wandb and (i % 100 == 0):\n",
    "                with t.no_grad():\n",
    "                    fake = netG(fixed_noise).detach().cpu()\n",
    "                wandb.log({\"images\": [wandb.Image(x, caption=\"epoch: \" + str(epoch) + \" iteration: \" + str(i)) for x in fake]})\n",
    "            \n",
    "            if max_epoch_duration is not None:\n",
    "                if time.time() - start_time > max_epoch_duration:\n",
    "                    break\n",
    "\n",
    "        print(\"Training complete\")\n",
    "\n",
    "    return netG, netD\n",
    "\n",
    "from GAN_implementation.models import Generator\n",
    "my_Generator = Generator(100, 64, 3, 512, 4)\n",
    "initialize_weights_generator(my_Generator)\n",
    "my_Discriminator = Discriminator(64, 3, 512, 4)\n",
    "initialize_weights_discriminator(my_Discriminator)\n",
    "trainloader = DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "discriminator_optimizer = optim.Adam(my_Discriminator.parameters(), lr=0.0002, betas=(0.5,0.999))\n",
    "generator_optimizer = optim.Adam(my_Generator.parameters(), lr=0.0002, betas=(0.5,0.999))\n",
    "\n",
    "my_Generator, my_Discriminator = train_generator_discriminator(\n",
    "    my_Generator,\n",
    "    my_Discriminator,\n",
    "    generator_optimizer,\n",
    "    discriminator_optimizer,\n",
    "    trainloader,\n",
    "    epochs=1,\n",
    "    max_epoch_duration=60*60*2,\n",
    "    log_netG_output_interval=100,\n",
    "    use_wandb=False,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_Generator.latent_dim_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 64, 64])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_Generator(t.randn(100, 100)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date and time: 12/06/2022, 12:12:35\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.0334e-06, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = t.randn(100, 100)\n",
    "real_images = next(iter(trainloader))[0]\n",
    "D_x = my_Discriminator(real_images).mean()\n",
    "fake = my_Generator(noise)\n",
    "D_G_z = my_Discriminator(fake.detach()).mean()\n",
    "\n",
    "(t.log(D_x).mean() + t.log(1 - D_G_z).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BCELoss.forward() missing 1 required positional argument: 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [83], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Binary Cross Entropy Loss\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mBCELoss()(D_x,)\n",
      "File \u001b[0;32m~/miniforge3/envs/arena/lib/python3.10/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: BCELoss.forward() missing 1 required positional argument: 'target'"
     ]
    }
   ],
   "source": [
    "#Binary Cross Entropy Loss\n",
    "import torch\n",
    "torch.nn.BCELoss()(D_x,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('arena')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b7e6b471291409f54dffbfbdfeccd6f1f2b5fb302e7acf62f723cf276419720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
