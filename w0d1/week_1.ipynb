{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from typing import Optional, Callable\n",
    "import ipywidgets as wg\n",
    "from fancy_einsum import einsum\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Discrete Fourier Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFT_1d(arr : np.ndarray,  inverse: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns the DFT of the array `arr`, using the equation above.\n",
    "    \"\"\"\n",
    "    N = len(arr)\n",
    "    power_term  = - np.outer(np.arange(N), np.arange(N)) * (2j * np.pi / N)\n",
    "    unity_arr = np.exp(power_term)\n",
    "    if not inverse:\n",
    "        return unity_arr @ arr\n",
    "    else: \n",
    "        return np.linalg.inv(unity_arr) @ arr\n",
    "\n",
    "def test_DFT_func_2(DFT_1d):\n",
    "\n",
    "    x = np.array([1, 2 - 1j, -1j, 2j-1])\n",
    "    y = DFT_1d(x)\n",
    "    y_expected  = np.array([2, -2 - 2j, -2j, 4+4j])\n",
    "    np.testing.assert_array_almost_equal(y, y_expected)\n",
    "\n",
    "utils.test_DFT_func(DFT_1d)\n",
    "test_DFT_func_2(DFT_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercises reminded me that its better to get exponent terms on their own rather and then apply np.exp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Fourier Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_function(func: Callable, x0: float, x1: float, n_samples: int = 1000):\n",
    "    \"\"\"\n",
    "    Calculates the approximation of the Riemann integral of the function `func`, \n",
    "    between the limits x0 and x1.\n",
    "\n",
    "    You should use the Left Rectangular Approximation Method (LRAM).\n",
    "    \"\"\"\n",
    "    step_size = (x1-x0)/n_samples\n",
    "    intervals = np.arange(x0,x1,step_size)    \n",
    "    return np.sum(np.array(list(map(func, intervals))))*step_size\n",
    "\n",
    "\n",
    "utils.test_integrate_function(integrate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_product(func1: Callable, func2: Callable, x0: float, x1: float):\n",
    "    \"\"\"\n",
    "    Computes the integral of the function x -> func1(x) * func2(x).\n",
    "    \"\"\"\n",
    "    return integrate_function(lambda x: func1(x)*func2(x), x0, x1)\n",
    "\n",
    "utils.test_integrate_product(integrate_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fourier_series(func: Callable, max_freq: int = 50):\n",
    "    \"\"\"\n",
    "    Calculates the fourier coefficients of a function, \n",
    "    assumed periodic between [-pi, pi].\n",
    "\n",
    "    Your function should return ((a_0, A_n, B_n), func_approx), where:\n",
    "        a_0 is a float\n",
    "        A_n, B_n are lists of floats, with n going up to `max_freq`\n",
    "        func_approx is the fourier approximation, as described above\n",
    "    \"\"\"\n",
    "    \n",
    "    a_0 = (1/np.pi)*integrate_function(func, -np.pi, np.pi) \n",
    "    A_n = [(1/np.pi)*integrate_product(func, lambda x: np.cos(n*x), -np.pi, np.pi)  for n in range(1, 1+max_freq)]\n",
    "    B_n = [(1/np.pi)*integrate_product(func, lambda x: np.sin(n*x), -np.pi, np.pi)   for n in range(1, 1+max_freq)]\n",
    "    func_approx =  lambda x: 0.5*a_0 + \\\n",
    "        sum([a*np.cos((n+1)*x) for n, a in enumerate(A_n)]) + \\\n",
    "        sum([b*np.sin((n+1)*x) for n, b in enumerate(B_n)])\n",
    "    \n",
    "    return (a_0, A_n, B_n,), np.vectorize(func_approx)\n",
    "\n",
    "step_func = lambda x: np.exp(np.sin(x)) * (np.sin(3*x) > 0)\n",
    "\n",
    "\n",
    "utils.create_interactive_fourier_graph(calculate_fourier_series, func = step_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Just be careful about what you're writing. Read each line carefully. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 40000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = np.linspace(-np.pi, np.pi, 2000)\n",
    "y = TARGET_FUNC(x)\n",
    "\n",
    "x_cos = np.array([np.cos(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = np.array([np.sin(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "\n",
    "a_0 = np.random.randn()\n",
    "A_n = np.random.randn(NUM_FREQUENCIES)\n",
    "B_n = np.random.randn(NUM_FREQUENCIES)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "\n",
    "    # TODO: compute `y_pred` using your coeffs, and the terms `x_cos`, `x_sin`\n",
    "    y_pred = 0.5*a_0 + A_n @ x_cos + B_n @ x_sin\n",
    "\n",
    "    # TODO: compute `loss`, which is the sum of squared error between `y` and `y_pred`\n",
    "    loss = ((y - y_pred)**2).sum()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(f\"{loss = :.2f}\")\n",
    "        coeffs_list.append([a_0, A_n.copy(), B_n.copy()])\n",
    "        y_pred_list.append(y_pred)\n",
    "\n",
    "    # TODO: compute gradients of coeffs with respect to `loss`\n",
    "    grad_pred_y = 2*(y_pred-y)\n",
    "    grad_coeffs_a_0 = 0.5*grad_pred_y\n",
    "    grad_coeffs_A_n = x_cos @  grad_pred_y\n",
    "    grad_coeffs_B_n = x_sin @ grad_pred_y\n",
    "\n",
    "    # TODO update weights using gradient descent (using the parameter `LEARNING_RATE`)\n",
    "    a_0 = a_o = LEARNING_RATE*grad_coeffs_a_0\n",
    "    A_n  = A_n - LEARNING_RATE*grad_coeffs_A_n\n",
    "    B_n = B_n - LEARNING_RATE*grad_coeffs_B_n\n",
    "\n",
    "result = utils.visualise_fourier_coeff_convergence(x, y, y_pred_list, coeffs_list)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 8928.85\n",
      "loss = 3670.25\n",
      "loss = 3570.74\n",
      "loss = 3565.41\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Tensor.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     A_n  \u001b[39m=\u001b[39m A_n \u001b[39m-\u001b[39m LEARNING_RATE\u001b[39m*\u001b[39mgrad_coeffs_A_n\n\u001b[1;32m     45\u001b[0m     B_n \u001b[39m=\u001b[39m B_n \u001b[39m-\u001b[39m LEARNING_RATE\u001b[39m*\u001b[39mgrad_coeffs_B_n\n\u001b[0;32m---> 47\u001b[0m result \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mvisualise_fourier_coeff_convergence(x, y, y_pred_list, coeffs_list)\n\u001b[1;32m     48\u001b[0m display(result)\n",
      "File \u001b[0;32m~/GithubRepositories/arena-v1/w0d1/utils.py:166\u001b[0m, in \u001b[0;36mvisualise_fourier_coeff_convergence\u001b[0;34m(x, y, y_pred_list, coeffs_list)\u001b[0m\n\u001b[1;32m    162\u001b[0m             fig\u001b[39m.\u001b[39mdata[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmarker\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mred\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m idx \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrgba(100, 100, 100, 0.1)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m slider\u001b[39m.\u001b[39mobserve(respond_to_slider)\n\u001b[0;32m--> 166\u001b[0m respond_to_slider(\u001b[39m\"\u001b[39;49m\u001b[39munimportant text to trigger first response\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    168\u001b[0m box_layout \u001b[39m=\u001b[39m wg\u001b[39m.\u001b[39mLayout(border\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msolid 1px black\u001b[39m\u001b[39m\"\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m20px\u001b[39m\u001b[39m\"\u001b[39m, margin\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m20px\u001b[39m\u001b[39m\"\u001b[39m, width\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m80\u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    170\u001b[0m \u001b[39mreturn\u001b[39;00m wg\u001b[39m.\u001b[39mVBox([wg\u001b[39m.\u001b[39mHBox([label, slider], layout\u001b[39m=\u001b[39mbox_layout), fig])\n",
      "File \u001b[0;32m~/GithubRepositories/arena-v1/w0d1/utils.py:160\u001b[0m, in \u001b[0;36mvisualise_fourier_coeff_convergence.<locals>.respond_to_slider\u001b[0;34m(change)\u001b[0m\n\u001b[1;32m    158\u001b[0m idx \u001b[39m=\u001b[39m slider\u001b[39m.\u001b[39mvalue \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m    159\u001b[0m \u001b[39mwith\u001b[39;00m fig\u001b[39m.\u001b[39mbatch_update():\n\u001b[0;32m--> 160\u001b[0m     fig\u001b[39m.\u001b[39mupdate_layout(title_text \u001b[39m=\u001b[39m get_title_from_coeffs(\u001b[39m*\u001b[39;49mcoeffs_list[idx]))\n\u001b[1;32m    161\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(fig\u001b[39m.\u001b[39mdata))\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    162\u001b[0m         fig\u001b[39m.\u001b[39mdata[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmarker\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mred\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m idx \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrgba(100, 100, 100, 0.1)\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/GithubRepositories/arena-v1/w0d1/utils.py:141\u001b[0m, in \u001b[0;36mget_title_from_coeffs\u001b[0;34m(a_0, A_n, B_n)\u001b[0m\n\u001b[1;32m    139\u001b[0m A_n_coeffs \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m + \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00ma_n\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mcos\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m (\u001b[39mstr\u001b[39m(n) \u001b[39mif\u001b[39;00m n\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m x}\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m (n, a_n) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(A_n, \u001b[39m1\u001b[39m)])\n\u001b[1;32m    140\u001b[0m B_n_coeffs \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m + \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mb_n\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msin\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m (\u001b[39mstr\u001b[39m(n) \u001b[39mif\u001b[39;00m n\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m x}\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m (n, b_n) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(B_n, \u001b[39m1\u001b[39m)])\n\u001b[0;32m--> 141\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m$y = \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m0.5\u001b[39m\u001b[39m*\u001b[39ma_0\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m + \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m A_n_coeffs \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m + \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m B_n_coeffs \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m$\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/arena/lib/python3.10/site-packages/torch/_tensor.py:660\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_meta:\n\u001b[1;32m    659\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem()\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(format_spec)\n\u001b[0;32m--> 660\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__format__\u001b[39;49m(\u001b[39mself\u001b[39;49m, format_spec)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Tensor.__format__"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "from copy import deepcopy\n",
    "\n",
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = torch.linspace(-torch.pi, torch.pi, 2000)\n",
    "y = TARGET_FUNC(x)\n",
    "list(torch.cos(x))\n",
    "x_cos = torch.tensor([list(torch.cos(n*x)) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = torch.tensor([list(torch.sin(n*x)) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "\n",
    "a_0 = torch.randn([1])\n",
    "A_n = torch.randn(NUM_FREQUENCIES)\n",
    "B_n = torch.randn(NUM_FREQUENCIES)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "\n",
    "    # TODO: compute `y_pred` using your coeffs, and the terms `x_cos`, `x_sin`\n",
    "    y_pred = 0.5*a_0 + A_n @ x_cos + B_n @ x_sin\n",
    "\n",
    "    # TODO: compute `loss`, which is the sum of squared error between `y` and `y_pred`\n",
    "    loss = ((y - y_pred)**2).sum()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(f\"{loss = :.2f}\")\n",
    "        coeffs_list.append([a_0, deepcopy(A_n), deepcopy(B_n)])\n",
    "        y_pred_list.append(y_pred)\n",
    "\n",
    "    # TODO: compute gradients of coeffs with respect to `loss`\n",
    "    grad_pred_y = 2*(y_pred-y)\n",
    "    grad_coeffs_a_0 = 0.5*grad_pred_y\n",
    "    grad_coeffs_A_n = x_cos @  grad_pred_y\n",
    "    grad_coeffs_B_n = x_sin @ grad_pred_y\n",
    "\n",
    "    # TODO update weights using gradient descent (using the parameter `LEARNING_RATE`)\n",
    "    a_0 = a_0 -  LEARNING_RATE*grad_coeffs_a_0\n",
    "    A_n  = A_n - LEARNING_RATE*grad_coeffs_A_n\n",
    "    B_n = B_n - LEARNING_RATE*grad_coeffs_B_n\n",
    "\n",
    "result = utils.visualise_fourier_coeff_convergence(x, y, y_pred_list, coeffs_list)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 3872.38\n",
      "loss = 251.42\n",
      "loss = 84.81\n",
      "loss = 68.17\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import utils\n",
    "from copy import deepcopy\n",
    "\n",
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = torch.linspace(-torch.pi, torch.pi, 2000)\n",
    "y = TARGET_FUNC(x)\n",
    "x_cos = torch.tensor([list(torch.cos(n*x)) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = torch.tensor([list(torch.sin(n*x)) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "\n",
    "a_0 = torch.randn((), requires_grad=True)\n",
    "A_n = torch.randn((NUM_FREQUENCIES), requires_grad=True)\n",
    "B_n = torch.randn((NUM_FREQUENCIES), requires_grad=True)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "    \n",
    "    # TODO: compute `y_pred` using your coeffs, and the terms `x_cos`, `x_sin`\n",
    "    y_pred = 0.5*a_0 + torch.matmul(A_n, x_cos) + torch.matmul(B_n, x_sin)\n",
    "    \n",
    "    # TODO: compute `loss`, which is the sum of squared error between `y` and `y_pred`\n",
    "    loss = torch.square(y - y_pred).sum()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(f\"{loss = :.2f}\")\n",
    "        coeffs_list.append([a_0.detach().item(), A_n.detach().numpy().copy(), B_n.detach().numpy().copy()])\n",
    "        y_pred_list.append(y_pred.detach())\n",
    "    \n",
    "    # TODO: compute gradients of coeffs with respect to `loss`\n",
    "    loss.backward()\n",
    "\n",
    "    \n",
    "    # TODO update weights using gradient descent (using the parameter `LEARNING_RATE`)\n",
    "    with torch.no_grad():\n",
    "        a_0 -= LEARNING_RATE * a_0.grad\n",
    "        A_n  -= LEARNING_RATE * A_n.grad\n",
    "        B_n -= LEARNING_RATE * B_n.grad\n",
    "\n",
    "        a_0.grad = None\n",
    "        A_n.grad = None \n",
    "        B_n.grad = None\n",
    "        \n",
    "\n",
    "result = utils.visualise_fourier_coeff_convergence(x, y, y_pred_list, coeffs_list)\n",
    "#display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 2377978.00\n",
      "loss = 12567.61\n",
      "loss = 219.10\n",
      "loss = 3.99\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import utils\n",
    "from copy import deepcopy\n",
    "\n",
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = torch.linspace(-torch.pi, torch.pi, 2000)\n",
    "y = TARGET_FUNC(x)\n",
    "x_cos = torch.tensor([list(torch.cos(n*x)) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = torch.tensor([list(torch.sin(n*x)) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "input = torch.concat((x_cos, x_sin))\n",
    "linear_model = torch.nn.Linear(len(x_cos)*2, len(y))\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "    \n",
    "    # TODO: compute `y_pred` using your coeffs, and the terms `x_cos`, `x_sin`\n",
    "    y_pred = linear_model(input.T)\n",
    "    \n",
    "    # TODO: compute `loss`, which is the sum of squared error between `y` and `y_pred`\n",
    "    loss = torch.square(y - y_pred).sum()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(f\"{loss = :.2f}\")\n",
    "        coeffs_list.append([a_0.detach().item(), A_n.detach().numpy().copy(), B_n.detach().numpy().copy()])\n",
    "        y_pred_list.append(y_pred.detach())\n",
    "    \n",
    "    # TODO: compute gradients of coeffs with respect to `loss`\n",
    "    loss.backward()\n",
    "\n",
    "    \n",
    "    # TODO update weights using gradient descent (using the parameter `LEARNING_RATE`)\n",
    "    with torch.no_grad():\n",
    "        for param in linear_model.parameters():\n",
    "            param -= param.grad*LEARNING_RATE\n",
    "\n",
    "        linear_model.zero_grad()\n",
    "        \n",
    "\n",
    "result = utils.visualise_fourier_coeff_convergence(x, y, y_pred_list, coeffs_list)\n",
    "#display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 2358885.50\n",
      "loss = 12776.69\n",
      "loss = 223.08\n",
      "loss = 4.07\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import utils\n",
    "from copy import deepcopy\n",
    "\n",
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = torch.linspace(-torch.pi, torch.pi, 2000)\n",
    "y = TARGET_FUNC(x)\n",
    "x_cos = torch.tensor([list(torch.cos(n*x)) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = torch.tensor([list(torch.sin(n*x)) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "input = torch.concat((x_cos, x_sin))\n",
    "linear_model = torch.nn.Linear(len(x_cos)*2, len(y))\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "optim = torch.optim.SGD(linear_model.parameters(), LEARNING_RATE)\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "    \n",
    "    # TODO: compute `y_pred` using your coeffs, and the terms `x_cos`, `x_sin`\n",
    "    y_pred = linear_model(input.T)\n",
    "    \n",
    "    # TODO: compute `loss`, which is the sum of squared error between `y` and `y_pred`\n",
    "    loss = torch.square(y - y_pred).sum()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(f\"{loss = :.2f}\")\n",
    "        coeffs_list.append([a_0.detach().item(), A_n.detach().numpy().copy(), B_n.detach().numpy().copy()])\n",
    "        y_pred_list.append(y_pred.detach())\n",
    "    \n",
    "    # TODO: compute gradients of coeffs with respect to `loss`\n",
    "    loss.backward()\n",
    "\n",
    "    \n",
    "    # TODO update weights using gradient descent (using the parameter `LEARNING_RATE`)\n",
    "    with torch.no_grad():\n",
    "        optim.step()\n",
    "        linear_model.zero_grad()\n",
    "        \n",
    "\n",
    "result = utils.visualise_fourier_coeff_convergence(x, y, y_pred_list, coeffs_list)\n",
    "#display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('arena')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b7e6b471291409f54dffbfbdfeccd6f1f2b5fb302e7acf62f723cf276419720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
