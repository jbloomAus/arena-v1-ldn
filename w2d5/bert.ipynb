{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import transformers\n",
    "from einops import rearrange\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import utils\n",
    "\n",
    "MAIN = __name__ == \"__main__\"\n",
    "DATA_FOLDER = \"./data\"\n",
    "DATASET = \"2\"\n",
    "BASE_URL = \"https://s3.amazonaws.com/research.metamind.io/wikitext/\"\n",
    "DATASETS = {\"103\": \"wikitext-103-raw-v1.zip\", \"2\": \"wikitext-2-raw-v1.zip\"}\n",
    "TOKENS_FILENAME = os.path.join(DATA_FOLDER, f\"wikitext_tokens_{DATASET}.pt\")\n",
    "\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    os.mkdir(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download(url: str, path: str) -> None:\n",
    "    \"\"\"Download the file from url and save it to path. If path already exists, do nothing.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, \"wb\") as file:\n",
    "            data = requests.get(url).content\n",
    "            file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset WikiText-2 - options are 2 and 103\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(DATA_FOLDER, DATASETS[DATASET])\n",
    "maybe_download(BASE_URL + DATASETS[DATASET], path)\n",
    "expected_hexdigest = {\"103\": \"0ca3512bd7a238be4a63ce7b434f8935\", \"2\": \"f407a2d53283fc4a49bcff21bc5f3770\"}\n",
    "with open(path, \"rb\") as f:\n",
    "    actual_hexdigest = hashlib.md5(f.read()).hexdigest()\n",
    "    assert actual_hexdigest == expected_hexdigest[DATASET]\n",
    "\n",
    "print(f\"Using dataset WikiText-{DATASET} - options are 2 and 103\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "z = zipfile.ZipFile(path)\n",
    "\n",
    "def decompress(*splits: str) -> str:\n",
    "    return [\n",
    "        z.read(f\"wikitext-{DATASET}-raw/wiki.{split}.raw\").decode(\"utf-8\").splitlines()\n",
    "        for split in splits\n",
    "    ]\n",
    "\n",
    "train_text, val_text, test_text = decompress(\"train\", \"valid\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 96 ammunition packing boxes ',\n",
       " ' Repaired : ',\n",
       " ' 2 @,@ 236 shotguns and rifles ( repaired mostly for troops in service ) ',\n",
       " ' 23 pistols ( repaired mostly for troops in service ) ',\n",
       " ' Received & Issued : ',\n",
       " ' 752 packages of ordnance and ordnance stores received and mostly issued to troops in service . ',\n",
       " ' Repaired and painted : ',\n",
       " ' 4 gun carriages ',\n",
       " ' Performed : ',\n",
       " ' Guard , office , and police duties . ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Du Fu \\'s popularity grew to such an extent that it is as hard to measure his influence as that of Shakespeare in England : it was hard for any Chinese poet not to be influenced by him . While there was never another Du Fu , individual poets followed in the traditions of specific aspects of his work : Bai Juyi \\'s concern for the poor , Lu You \\'s patriotism , and Mei Yaochen \\'s reflections on the quotidian are a few examples . More broadly , Du Fu \\'s work in transforming the lǜshi from mere word play into \" a vehicle for serious poetic utterance \" set the stage for every subsequent writer in the genre . ',\n",
       " ' In the 20th century , he was the favourite poet of Kenneth Rexroth , who has described him as \" the greatest non @-@ epic , non @-@ dramatic poet who has survived in any language \" , and commented that , \" he has made me a better man , as a moral agent and as a perceiving organism \" . ',\n",
       " ' ',\n",
       " ' = = = Influence on Japanese literature = = = ',\n",
       " ' ',\n",
       " \" Du Fu 's poetry has made a profound impact on Japanese literature , especially on the literature from the Muromachi period and on scholars and poets in the Edo period , including Matsuo Bashō , the very greatest of all haiku poets . Even in modern Japanese , the term Saint of Poetry ( 詩聖 , shisei ) is mostly synonymous with Du Fu . \",\n",
       " ' Until the 13th century , the Japanese preferred Bai Juyi above all poets and there were few references to Du Fu , although his influence can be seen in some kanshi ( \" Chinese poetry made by Japanese poets \" ) anthologies such as Bunka Shūreishū in the 9th century . The first notable Japanese appreciator of Du Fu \\'s poetry was Kokan Shiren ( 1278 – 1346 ) , a Rinzai Zen patriarch and one of the most prominent authors of the literature of the Five Mountains ; he highly praised Du Fu and made a commentary on some poems of Du Fu from the perspective of a Zen priest in Vol . 11 of Saihokushū . His student Chūgan Engetsu composed many kanshi which were clearly stated \" influenced by Du Fu \" in their prefaces . Chūgan \\'s student Gidō Shūshin had close connection with the Court and Ashikaga Shogunate and propagated Du Fu \\'s poetry in the mundane world ; one day Nijō Yoshimoto , the Kampaku regent of the Court and the highest authority of renga poetry , asked Gidō , \" Should I learn the poetry of Du Fu and Li Bai ? \" Gidō dared to reply , \" Yes if you do have enough capability . No if do not . \" Since then , there had been many seminars on Du Fu \\'s poetry both in Zen temples and in the aristocratic society , and as a result his poetry was often cited in Japanese literature in the Muromachi period , e.g. , Taiheiki , a historical epic in the late 14th century , and some noh plays such as Hyakuman , Bashō , and Shunkan . ',\n",
       " \" During the Kan 'ei era of the Edo period ( 1624 – 1643 ) , Shào Chuán ( 邵傳 ) of the Ming Dynasty 's Collective Commentary on Du Fu 's Lǜshi ( 杜律集解 , Toritsu Shikkai ) was imported into Japan , and it gained explosive popularity in Confucian scholars and chōnin ( townspeople ) class . The commentary established Du Fu 's fame as the highest of all poets ; for instance , Hayashi Shunsai , a notable Confucian scholar , commented in Vol . 37 of Gahō Bunshū that Zǐměi [ Du Fu ] was the very best poet in history and praised Shào Chuán 's commentary for its simplicity and readability , while he criticized old commentaries during the Yuan Dynasty were too unfathomable . Matsuo Bashō , the greatest haiku poet , was also strongly influenced by Du Fu ; in Oku no Hosomichi , his masterpiece , he cites the first two lines of A Spring View ( 春望 ) before a haiku as its introduction and also many of his other haiku have similar wording and themes . It is said that when he died in Osaka during a long travel , a copy of Du Fu 's poetry was found with him as one of a few precious items which he was able to carry around . \",\n",
       " ' ',\n",
       " ' = = Translation = = ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_1d(tokenizer, lines: list[str], max_seq: int) -> t.Tensor:\n",
    "    '''Tokenize text and rearrange into chunks of the maximum length.\n",
    "\n",
    "    Return (batch, seq) and an integer dtype.\n",
    "    '''\n",
    "    tokenizer\n",
    "\n",
    "if True:\n",
    "    max_seq = 128\n",
    "    print(\"Tokenizing training text...\")\n",
    "    train_data = tokenize_1d(tokenizer, train_text, max_seq, 100)\n",
    "    print(\"Training data shape is: \", train_data.shape)\n",
    "    print(\"Tokenizing validation text...\")\n",
    "    val_data = tokenize_1d(tokenizer, val_text, max_seq)\n",
    "    print(\"Tokenizing test text...\")\n",
    "    test_data = tokenize_1d(tokenizer, test_text, max_seq)\n",
    "    print(\"Saving tokens to: \", TOKENS_FILENAME)\n",
    "    t.save((train_data, val_data, test_data), TOKENS_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('arena')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b7e6b471291409f54dffbfbdfeccd6f1f2b5fb302e7acf62f723cf276419720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
